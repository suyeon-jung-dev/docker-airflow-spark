# docker-airflow-spark

### ğŸ‡°ğŸ‡· í•œê¸€ ë¬¸ì„œëŠ” [ì•„ë˜](#dockerë¡œ-airflow_spark-ì—°ë™í•˜ê¸°)ë¥¼ ë´ì£¼ì„¸ìš”!

This project contains the following containers:

* postgres
    * Image: postgres:13
    * Database Port: 5432
    * User: airflow
    * PWD: airflow
    * References: https://hub.docker.com/_/postgres

* redis
  * Image: redis:7.2-bookworm

* airflow-webserver
    * Image: apache/airflow:2.9.2
    * Port: 8080

* spark: Spark Master
    * Image: bitnami/spark:3.1.2
    * Port: 8181
    * References:
        * https://github.com/bitnami/bitnami-docker-spark
        * https://hub.docker.com/r/bitnami/spark/tags/?page=1&ordering=last_updated

* spark-worker-*: Spark workers
    * Image: bitnami/spark:3.1.2
    * References:
        * https://github.com/bitnami/bitnami-docker-spark
        * https://hub.docker.com/r/bitnami/spark/tags/?page=1&ordering=last_updated

* jupyter-spark: Jupyter notebook with pyspark for interactive development.
    * Image: jupyter/pyspark-notebook:spark-3.1.2
    * Port: 8888
    * References:
        * https://hub.docker.com/layers/jupyter/pyspark-notebook/spark-3.1.2/images/sha256-37398efc9e51f868e0e1fde8e93df67bae0f9c77d3d3ce7fe3830faeb47afe4d?context=explore
        * https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-pyspark-notebook
        * https://hub.docker.com/r/jupyter/pyspark-notebook/tags/

## How to start

1. run in background with build
```console
docker-compose up --build -d
```

2. check websites
Airflow: http://localhost:8080

```txt
user: airflow
password: airflow
```

Spark Master: http://localhost:8181

Postgres - Database airflow:
* Server: localhost:5432
* Database: airflow
* User: airflow
* Password: airflow

Jupyter Notebook: http://127.0.0.1:8888

Following command will show you the URLs of running servers with their tokens, which you can copy and paste into your browser.
```console
docker logs -f docker-airflow-spark-jupyter-spark-1
```


## Spark

Safely way to stop Spark container 
```console
docker stop $(docker-compose ps | grep spark | awk '{print $1}')
```

or using Docker Compose:

```console
docker-compose ps | grep spark | awk '{print $1}'
```





------
From here, This document written in korean ğŸ˜Š
# dockerë¡œ airflow_spark ì—°ë™í•˜ê¸°

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ì»¨í…Œì´ë„ˆë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤ :)

* postgres
    * Image: postgres:13
    * Database Port: 5432
    * User: airflow
    * PWD: airflow
    * References: https://hub.docker.com/_/postgres

* redis
    * Image: redis:7.2-bookworm

* airflow-webserver
    * Image: apache/airflow:2.9.2
    * Port: 8080

* spark: Spark Master
    * Image: bitnami/spark:3.1.2
    * Port: 8181
    * References:
        * https://github.com/bitnami/bitnami-docker-spark
        * https://hub.docker.com/r/bitnami/spark/tags/?page=1&ordering=last_updated

* spark-worker-*: Spark workers
    * Image: bitnami/spark:3.1.2
    * References:
        * https://github.com/bitnami/bitnami-docker-spark
        * https://hub.docker.com/r/bitnami/spark/tags/?page=1&ordering=last_updated

* jupyter-spark: Jupyter notebook with pyspark for interactive development.
    * Image: jupyter/pyspark-notebook:spark-3.1.2
    * Port: 8888
    * References:
        * https://hub.docker.com/layers/jupyter/pyspark-notebook/spark-3.1.2/images/sha256-37398efc9e51f868e0e1fde8e93df67bae0f9c77d3d3ce7fe3830faeb47afe4d?context=explore
        * https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-pyspark-notebook
        * https://hub.docker.com/r/jupyter/pyspark-notebook/tags/

## ì‹¤í–‰ë°©ë²•
### ì „ì œì¡°ê±´
- Docker Demon (Docker Desktop ì´ ë¡œì»¬ì— ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)

1. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•˜ë ¤ë©´ ë³¸ í”„ë¡œì íŠ¸ ìµœìƒë‹¨ ìœ„ì¹˜ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰ì‹œì¼œì£¼ì„¸ìš”
```console
docker-compose up -d
```

2. ê° ì„œë²„ ì ‘ì†í•´ì„œ í™•ì¸í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤. ê° ì„œë²„ê°€ ì˜¬ë¼ì˜¤ëŠ”ë° ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë‹ˆ Docker Desktop ì—ì„œ ë¡œê·¸ í™•ì¸ í•˜ë©´ì„œ ì‹¤í–‰í•´ì£¼ì‹œë©´ ë”ìš± ì¢‹ìŠµë‹ˆë‹¤. 

Airflow: http://localhost:8080

```txt
user: airflow
password: airflow
```

Spark Master: http://localhost:8181

Postgres - Database Connection Test:

* Server: localhost:5432
* Database: airflow
* User: airflow
* Password: airflow

Jupyter Notebook: http://127.0.0.1:8888

ì£¼í”¼í„° ë…¸íŠ¸ë¶ì€ ì„œë²„ ë¡œê·¸ë¥¼ í†µí•´ í™•ì¸ë˜ëŠ” í† í°ì •ë³´ë¥¼ ê¸°ì…í•´ì£¼ì„¸ìš”.
ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë¡œê·¸ í™•ì¸í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.

```console
docker logs -f docker-airflow-spark-jupyter-spark-1

## ë¡œê·¸ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸ ë˜ëŠ” ì •ë³´ ì¤‘ì—ì„œ ex) http://localhost:8888/?token=c8de56fa... 
## token ê°’ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.
```


## ìŠ¤íŒŒí¬ ì„œë²„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•˜ëŠ” ë°©ë²•

ë„ì»¤ ëª…ë ¹ì–´ë¡œ ì¢…ë£Œí•˜ê¸°
```console
docker stop $(docker-compose ps | grep spark | awk '{print $1}')
```
ì•„ë‹ˆë©´... 
Docker Compose ëª…ë ¹ì–´ë¡œ ì¢…ë£Œí•˜ê¸°

```console
docker-compose ps | grep spark | awk '{print $1}'
```
